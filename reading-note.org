* 读书笔记
** 领导和管理
   + 领导是与“拉”相关的活动，设定目的地和通往目的地的路线图
   + 管理是与“推”相关的活动，设法到达目的地







* 周边小常识
** unicode和UTF-8
    unicode是一个编码规范，它纳入了世界上所有的字符，赋予每个字符一个唯一编码。如一个汉字在unicode里对应一个2字节编码，这个编码在支持unicode的系统里都能被正确识别。
    单从编码规范的角度来看，unicode跟计算机（可以）没有任何关系。
    unicode定义了字符的编码（码值），但是并未定义计算机中该如何存储、传送内容，所以，出现了UTF(unicode transformation format)，有UTF-8和UTF-16。UTF-16即任何字符都用两个字节存放，这对英文为主的环境显然太浪费，但是对中文为主的环境比较适合。UTF-8是变长编码（1到3字节），解决了浪费问题，缺点是编码规则复杂一些。
    
*** utf-8的表示形式
    utf8根据当前字节的第一个bit来确定使用几个字节来表示（存储）一个unicode，这是约定的规则.你用UTF-8来表示时必须遵守这样的规则.我们知道UTF-16不需要用啥字符来做标志,所以两字节也就是2的16次能表示65536个字符.而UTF-8由于里面有额外的标志信息,所有一个字节只能表示2的7次方128个字符,两个字节只能表示2的11次方2048个字符.而三个字节能表示2的16次方,65536个字符.由于"汉"的编码27721大于2048了所有两个字节还不够,只能用三个字节来表示.

    0xxxxxxx,如果是这样的01串,也就是以0开头后面是啥就不用管了XX代表任意bit.就表示把一个字节做为一个单元.就跟ASCII完全一样.
    110xxxxx 10xxxxxx.如果是这样的格式,则把两个字节当一个单元
    1110xxxx 10xxxxxx 10xxxxxx 如果是这种格式则是三个字节当一个单元.
    
    所有要用1110xxxx 10xxxxxx 10xxxxxx这种格式.把27721对应的二进制从左到右填充XXX符号，于是就出现了Big-Endian,Little-Endian的术语.Big-Endian就是从左到右,Little-Endian是从右到左.
    由上面我们可以看出UTF-8需要判断每个字节中的开头标志信息,所以如果一当某个字节在传送过程中出错了,就会导致后面的字节也会解析出错.而UTF-16不会判断开头标志,即使错也只会错一个字符,所以容错能力强.

*** 如何区分文件是哪种编码
    前面说了要知道具体是哪种编码方式,需要判断文本开头的标志,下面是所有编码对应的开头标志

    EF BB BF　　　 UTF-8
    FE FF　　　　　UTF-16/UCS-2, little endian
    FF FE　　　　　UTF-16/UCS-2, big endian
    FF FE 00 00　　UTF-32/UCS-4, little endian.
    00 00 FE FF　　UTF-32/UCS-4, big-endian.

    其中的UCS就是前面说的ISO制定的标准,和Unicode是完全一样的,只不过名字不一样.ucs-2对应utf-16,ucs-4对应UTF-32.UTF-8是没有对应的UCS


* python 学习
** 类与继承
   1. Type函数可以动态生成类型（class），实质上pyton创建类的过程也是调用type()函数
   2. type()函数可以动态创建类，metaclass可以动态控制类（增加方法、属性和过程），类似java动态生成类（动态字节码）
   3. 装饰器在python中类似动态代理，装饰一个函数的调用，但是不影响函数执行。
   4. 枚举类需继承Enum，直接通过ClassName.enumName获取枚举

** 生成器generator
   与列表生成式的样子很像，只不过generator使用小括号包裹，而列表生成式用中括号，
   如:g = (x * x for x in range(10))
   
   generator只定义了计算规则，一边循环一遍计算。反复调用next()方法获取下一个返回值。一般永远不会使用next方法，因为generator用for循环来迭代它。
   如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator。yield关键字在generator中负责中断，下次调用next()在此中断的地方开始。


* java 并发编程
** 重排序
   java程序从编译到运行，会经历3个重排序过程，分别是
   1. 编译重排序
   2. 指令重排序
   3. 内存系统重排序


* java 基础
** java 集合数据结构
   1. HashMap内部数据结构是一个二元结构，外层是一个数组，数组内元素则是一个列表。存取删元素时，会先通过key的hashcode取模，确定key在数组中的位置，再从链表中通过equal确定真正的key。
      + 取模运算速度不及位运算，在hashMap中，巧妙的使用位运算来达到取模的效果，h & (length -1)。这决定了hashMap的length必须为2的次方
      + 在存取删过程中，全程都是key在参与运算，valve做为附属信息只在最后存入了数据中
        
   2. TreeMap是一个有序的Map，其内部使用红黑树保证排序。
      + 红黑树有几个特性，1 根节点和叶子节点必须为黑色；2 红色的子节点必须为黑色；3 任意节点到到该节点的子孙节点所有路径上包含相同数目的黑节点。红黑树是接近平衡的二叉树
      + 红黑树的常用操作为左旋和右旋

* DB 基础
** B树 B-树 B+树 B*树
   1. B树既是二叉搜索树，有如下特性。在接近平衡二叉树时，效率最高（相当于二分查找），但是在进过多次增删后，可能会出现所有元素朝向一边（线性）的情况。所以如何保证B树结构分布均匀的平衡算法是平衡二叉树的关键。平衡算法是B树中插入和删除节点时的策略
      + 所有非叶子节点至多拥有两个儿子（left和right）
      + 非叶子节点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树
      + 所有节点存储一个关键字
        
   2. B-树是多路搜索树
      + 同时限定了层级和分叉个数
      + 关键字也是分布在整棵树中
      + 非根非叶子节点里的关键字表明了子树的数值范围，同时也表明了子树的个数。如关键字为8、12，那么会有3棵子树分别小于8、大于8小于12、大于12
      + 搜索可以在非叶子节点中结束
      + 元素有M/2的限定，在插入结点时，如果结点已满，需要将结点分裂为两个各占M/2的结点；删除结点时，需将两个不足M/2的兄弟结点合并；


   1. B+树跟B-树类似，也是多路搜索树
      + 非根非叶子节点不存储关键字，所有关键字均在叶子节点，非根非叶子节点即作为叶子节点的索引（适合存储和文件系统）
      + 非根非叶子节点也是存储子树的数值范围，但是范围略有不同，如关键字8和12，那么会有2棵子树，分别是大于8小于12、大约12
      + 叶子节点持有数据链表指针，用于搜索数据

   2. B* 树
      + 为非根非叶子节点也增加一个链表指针
      + 将节点的利用率从1/2提高到2/3

* 高等数学
** 主要内容
一元、多元函数的微分学和积分学，矢量代数，空间解析几何，无穷级数和微分方程

** 学习目的
掌握高等数学的基本知识，基本理论，基本计算方法，提高数学素养。
培养抽象思维和逻辑推理的能力，和辩证的思想方法。
培养空间想象能力，分析问题和解决问题的能力
* luence
** 如何创建索引，步骤如下
*** 第一步，原文档，document，可以是文本，文档（word）、html；
*** 第二步，将原文档传递给分词组件（Tokenizer）
分词组件会做以下几件事情，此过程称为tokenize
1. 将文档分为一个一个独立的单词；
2. 去除标点符号；
3. 去掉停词；
*** 第三步，将得到词元传给语言处理组件（linguistic Process）
语言处理组件主要对词元做一些同语言相关的处理，例如对英语来说
1. 变为小写；
2. 将单词缩减为词根形式，如cars到car等，这种操作称为stemming；
3. 将单词转变为词根形式，如drove到drive等，这种操作成为lemmatization
*** 第四步，将得到的词（term）传给索引组件（Indexer）
1. 利用得到的词（term）创建一个字典；
2. 对字典按字母顺序排序；
3. 合并相同的词成为文档倒排（Posting List）链表；其中包含document Frequency,Frequency

** 如何查询索引
*** 第一步，查询语句
查询语句同我们普通的语言一样，也有一定语法；
*** 第二步，对查询语句进行词法分析、语法分析及语言处理
1. 词法分析主要用来识别单词和关键字；
2. 语法分析主要根据查询语句的语法规则来形成一颗语法树；
3. 语言处理同创建过程中的语言处理几乎相同；
*** 第四步，根据得到文档和查询语句的相关性，对结果进行排序
1. 找出词（term）对文档的重要性称为计算词的权重（term weight）的过程。计算词的权重有两个参数，一个是词（term），一个是文档（document）
+ term frequency(tf)，即此term在文档中出现了多少次，tf越大说明越重要；
+ document frequency（df），即有多少文档包含此term，df越大越不重要；
+ 根据上面两个参数使用负责的数学公式得出权重
2. 判断词之间的关系从而得到文档相关性的过程应用一种叫向量空间模型的算法（Vector Space model）
+ 我们把文档（document）所有词term的权重（term weight）看作一个向量；
+ 同样把查询语句看作一个简单的文档，也用向量表示；
+ 把所有搜索出的文档向量放到一个N维空间中，每个词是1维；
+ 与查询语句向量夹角越小，则相关性越大。
** luence 文件结构
* elasticsearch
** es 元素
1. 节点，即运行实例
2. index，es中的关键实体，类似与DB中的库。一个es可以拥有多个Index。
3. 分片(shards)，es可以把每个Index分成多个小索引，每个小索引就是分片。
+ 主分片（Primary shard） 索引的子集，索引可以切分成多个分片（默认是5个），分布到不同的集群节点上。分片对应的是 Lucene 中的索引。
+ 副本分片（Replica shard）每个主分片可以有一个或者多个副本（默认1个）
4. type相当于数据库中的table概念，mapping是针对 Type 的。同一个索引里可以包含多个 Type。
5. Mapping 相当于数据库中的schema，用来约束字段的类型，不过 Elasticsearch 的 mapping 可以自动根据数据创建。
6. 文档（Document) 相当于数据库中的row
7. 字段（Field）相当于数据库中的column。
8. 分配（Allocation） 将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。
* RocketMQ
** msg producer
1. 实例化DefaultMQProducer类，设置producerGroup,namesrv,instanceName;
2. start(),启动netty
3. send()，获取topic路由信息，queue list，选择broker发送消息

** msg consumer
1. 实例化DefaultMQConsumer类，设置consumrGroup,namesrv,instanceName,topic
2. 注册回调，启动start()
   + 获取topic路由信息，queue list
   + 启动PullService，借助Blockingqueue实现长轮询，快速响应和拉取消息；
   + RebalanceService触发一个CountDownLatch条件，作为PullService的启动点，之后每30s从namesrv拉取路由和queue list，如果发现新路由则加入进来。

* 方法论
  时刻抓住主要工作线索，围绕线索开展学习和创作
* 程序员
  从并发角度考虑程序设计和debug

* 技术拼图
** Nginx
   自由、开源、稳定高效的web服务器，同时也是一个IMAP、POP3、SMTP代理服务器；nginx可以作为一个HTTP服务器进行网站的发布处理，另外nginx可以作为反向代理进行负载均衡的实现。
*** Nginx配置详解

** kafka
   kafka配置中listener是对外暴露域名端口的，如果不配默认主机名，会记入到zookeeper的brokers中。这里就有可能导致机器名是字符串，而网络中其他主机不认识，连接不上的情况。
** java
*** 双亲委派模型
    让class和classloader具有优先级和层次关系；
    确保系统类库不被篡改；
    被同一个classloader加载的class才可以比较；
*** java并发
1. volatile
JMM通过汇编LOCK# 语义实现两个功能，1使当前缓存回写系统内存，2缓存一致性协议使其他CPU缓存行失效；
2. synchronized
jvm定义的同步机制，通过monitor做到线程同步
3. 原子操作
在CPU中，通过总线锁或缓存锁来保证同一时刻只有一个CPU(线程)操作。
而在java中，通过cas自旋和锁来实现原子操作
4. java内存模型
堆、栈（CPU缓存）、计数器、方法区和本地方法区。
并发程序中，JMM决定共享变量何时对另一个线程可见。
5. 重排序
从java源代码到最终执行的指令序列，会分别经历3中重排序，1编译器优化重排序，2指令级并行重排序，3内存系统重排序。
1属于编译器重排序，2和3属于处理器重排序。

6. 内存屏障
在处理器中，通过在指令间插入内存屏障（Memory Barriers或Memory Fence）来阻止重排序，确定load和store关系，各处理器都支持store-load重排，它是一个全能型屏障，同时具备其他3个屏障的效果。

7. happens-before关系
从jdk1.5开始，java使用happens-before关系来阐述操作之间内存可见性。在JMM中，如果一个操作的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系.
这里两个操作，可以是一个线程之内，也可以是在不同线程里。

** elasticsearch
*** 节点类型
    1. master 只有一个，如果原master故障，自动选取一个成为新master。master节点负责索引新建和删除，跨节点shards分发；

*** DSL
    dsl分为两部分，query和filter，query会进行分词，查询并打分；filter则筛选掉那些不符合条件的记录。
    所以，推荐做法是，在query部分放影响打分的查询条件，其他的放到filter中。
** 分布式架构中的面向对象与异常处理
*** 微服务发展历程
   随着互联网的发展，服务端架构也从单应用到集群+服务总线，逐渐升级为分布式、微服务架构。这是服务端架构在高可用、健壮性、易用性上逐步完善过程。
   【图】
*** springcloud和dubbo调用过程
    【图】

*** 分布式系统的面向对象
   架构演进过程中，随着系统的拆分，以及技术上的取舍（如采用restful+json做服务调用，或者通过泛化调用），系统逐渐失去了面向对象的特性，使维护性大大降低【贴图】，并且妨碍开发效率【贴图】。同时在分布式系统中，原有的异常信息传递成为被忽视的地方。要么直接try catch，要么不管，导致上层调用失败时，问题定位非常困难。
   【restful+json调用示例图】

*** 异常处理方式
   throw
   异常处理方式

*** 分布式系统的异常处理

*** 分布式系统中的继承
** c/c++
inline--内联函数
编译器直接用函数定义替换掉函数调用点。
inline建议直接在h文件中定义
inline函数只能包含小而精的代码逻辑，不能包含while、switch等复杂逻辑，并且不能是递归函数。
类成员函数默认是inline
** 大数据
*** hdfs
HDFS（Hadoop Distributed File System）是Hadoop项目的核心子项目，是分布式计算中数据存储管理的基础，是基于流数据模式访问和处理超大文件的需求而开发的，可以运行于廉价的商用服务器上。它所具有的高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征为海量数据提供了不怕故障的存储，为超大数据集（Large Data Set）的应用处理带来了很多便利。
HDFS 采用Master/Slave的架构来存储数据，这种架构主要由四个部分组成，分别为HDFS Client、NameNode、DataNode和Secondary NameNode。
** ai
*** keras
Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行.
Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

*** tensorflow
+ tensor 张量
+ 占位符
+ dataset数据集
+ 层
** python
** io
iostat -d -x -k 1 10
** tcp/ip
*** 分层
| 网络分层 | 示例                   |
|----------+------------------------|
| 应用层   | telnet,ftp,email       |
| 传输层   | tcp,udp                |
| 网络层   | ip,icmp,IGMP           |
| 链路层   | 设备驱动程序以及接口卡 |
|----------+------------------------|

*** 数据传输
tcp传给ip 的数据称为tcp报文段，简称tcp端,tcp segments
ip 传给网络层的数据单元称为ip数据报，IP datagram
通过以太网传输的比特流称作帧，frame，46-1500字节之间

* matric

** Gauges
Gauge是最简单的度量类型，只有一个简单的返回值，他用来记录一些对象或者事物的瞬时值。

** Counter
Counter是一个简单64位的计数器，他可以增加和减少。

这种计数器也可以用来统计诸如当前有多少人在线，或者服务器中有多少处于有效期内的session

** Meters
Meter是一种只能自增的计数器，通常用来度量一系列事件发生的比率。他提供了平均速率，以及指数平滑平均速率，以及采样后的1分钟，5分钟，15分钟速率。

** Histograms
Histrogram是用来度量流数据中Value的分布情况，Histrogram可以计算最大/小值、平均值，方差，分位数（如中位数，或者95th分位数），如75%,90%,98%,99%的数据在哪个范围内。

** Timer
Timer是Histogram跟Meter的一个组合，比如要统计当前请求的速率和处理时间。
* 每日阅读
** 2019-07-07
   1. 分布式系统特点，对等性、并发性、无全局时钟
      问题：网络分区（脑裂），网络异常、三态
   2. cap和base
      一致性、可用性，分区容错性
      基本可用，软状态，最终一致
   3. 2pc
      事务操作阶段和事务提交阶段
      问题：脑裂、阻塞（主要）、锁定资源

** 2019-07-08
   1. 3pc
      canCommit，preCommit和doCommit
      特点：解决了阻塞范围，并未解决一致性
   2. paxos
      Proposer：分两阶段提交提案，prepare和accept。prepare阶段会受到pomise，如果收到大于半数的pomise，则向pomise发送accept请求；accept阶段会受到accepted，如果超过半数accepted，则成功；
      Acceptor：在prepare阶段，如果没有accepted一个值，则会不停认同提案号最大的那个提案，返回ok，在accept阶段，如果编号相同则返回accepted，小于当前编号则rejected，大于编号则保存新编号，如果已accepted一个提案，则会返回（acceptedProposal，acceptedValue）
** 2019-07-09
   1. docker
      docker最大的特点，轻。在docker之前，虚拟化只在操作系统层级，vmware和OpenStack
      docker其他特点，进程级，秒级启动、资源占用少，弹性、负载、动态
      docker本身并不是容器，它是创建容器的工具，是应用容器的引擎

      docker 搭建（build）、发送（ship）、运行（run）。build once，run everywhere

      docker的三大核心概念，镜像（Image），容器（container），仓库（Repository）
      Image说白了就是一个特殊的系统文件，包含容器运行所需的程序、库、资源、配置等，Image不包含任何动态信息，其内容在构建后也不会改变；
   2. k8s
      k8s是google开源的基于容器的资源管理平台，用来解决容器（docker）的编排、管理、调度等问题
      一个k8s系统，通常称为k8s集群，包含master节点和一群node节点
      master节点包含api server，scheduler，controller manager和etcd
      node节点包含docker、kubelet,kube-proxy,fluentd,kube-dns，还有pod

** 2019-07-16
elastic-job
1. AbstractJobBeanDefinitionParser由spring扩展点加载
2. spring扩展点加载的是初始化方法，真正加载应该在最后（由配置决定要不要延迟）
3. 初始化coreconfiguration，registy供init方法调用。init方法在beandefinition指定；
4. job信息存入zk

mysql
mysql提供多种存储引擎，用户还可以按照协议自定义存储引擎。innodb原本也是第三方引擎，擅长处理oltp业务，MyISAM引擎不支持事务，仅支持表级锁，擅长处理olap业务

操作日志记录
记录操作人，ip，类型，详细输入参数，有限的返回报文

** 2019-07-17
mysql
innodb体系架构
1. 内存
   + 缓冲池，包括数据页、索引页、undo页、insert buffer，自适应哈希索引 adaptive hash index，innodb锁信息lock info，数据字典data dictionary
   + LRU list，free list和flush list。



2. 后台线程
   + master thread
   + io thread
   + purge thread
   + page cleaner thread


个人竞争力思考
1. 情绪容易波动，主动性较差，容易消极
2. 面对突发会手忙脚乱

1. 技术广度大
2. 能够因地制宜设计合理的程序架构
3. 能够读书

** 2019-07-18
mysql
insert buffer 解决非聚集索引构建时的离散读盘问题
double write 二次写，提高数据页可靠性
自适应哈希索引
异步iO
启动关闭与恢复机制

** 2019-07-19
mysql文件
1. 参数文件 my.cnf
2. 日志文件
   + 错误日志 error log
   + 二进制日志 binlog
   + 慢查询日志 slow query log
   + 查询日志 log
3. socket文件
4. pid文件
5. mysql表结构文件
6. 存储引擎文件
   + 表空间文件ibdata
   + 重做日志ib_logfile0,ib_logfile1

** 2019-07-20
mysql表
1. 在innodb存储引擎中，表都是根据主键顺序存放的，这种存储方式的表称作索引组织表 index organized table
2. innodb所有数据都被逻辑地存放在一个空间中，称之为表空间tablespace。表空间又由段（segment），区（extent），页（page或block）组成

** 2019-07-23
1. quartz远程调度实现，quartz scheduler架构
2. springboot + mybatis 多数据源，定义数据源DataSource，定义sqlsessionfactory，注入mapper（xml或者dao）

** 2019-07-24
聚集索引：数据行的物理顺序与列值（一般是主键）的逻辑顺序相同，一个表中只能有一个聚集索引。可以认为聚集索引是索引组织表特有的。
非聚集索引：聚集索引以外的其他索引，分为普通索引、唯一索引、全文索引。

堆表
1. 堆就是无序数据的集合，索引就是将数据变得有序，在索引中键值有序，数据还是无序的；
2. 数据存放在数据里，索引存放在索引里；
3. 堆表中，主键索引和普通索引一样，和非空唯一索引没有区别。索引叶子节点存放的是指向堆表数据的指针（可以是页码和偏移量），指向物理地址，没有回表的说法；
4. mysql的myISAM，Oracle，pg都支持的是堆表

索引组织表
1. 索引组织表是一个B树存储结构，是按主键有序的，可变的。
2. 对于主键索引，叶子节点存放了所有行数据（即聚集索引），其他索引称为辅助索引，只存储索引键和主键；
3. innodb就是索引组织表
4. inndb数据存放在聚集索引中

** 2019-07-25
osgi模块化和面向对象所带来的能力都通过控制可见性和可用性来保证高内聚低耦合，只是粒度不一样，前者在组件层面，后者在对象层面。
在标准的jar包的manifest文件中添加一些组件（bundle）的模块化特征（metadata）后，jar包就变成了一个bundle。
bundle和普通jar包最大的区别就在于元数据。
Bundle元数据的目的在于准确描述模块化相关的bundle特征，让OSGi框架对bundle进行各种处理工作（比如依赖解析，强制封装等），元数据主要有三部分：
1. 可读信息（可选）.name doc url copyright等，osgi会忽略可读信息
2. bundle标识（必须），Bundle-SymbolicName，Bundle-Version
   bundle标识符用于唯一的标识一个bundle
3. 代码可见性
   代码可见性用于定义内部与外部代码。在JavaSE中的jar包如果放在classpath里，那么jar包对classpath下的所有程序都是可见的，并且可见性不能改变。而OSGi标准定义了如下的属性用于描述代码的可见性：
   Bundle-ClassPath：定义了形成bundle的所有代码所在的位置，Java 中的classpath是定义的jar包的位置，而Bundle-ClassPath属性描述的是bundle内部类在bundle中的路径。例如：Bundle-ClassPath:.,other-classes/,embedded.jar
   Export-Package：显式暴露需要和其它bundle共享的代码，每个包之间用逗号分隔，每个包可用修饰词来修饰包的其它特征，Export-Package: org.serc.hellworld; vendor=”SERC”,org.serc.hellworld.impl; vendor=”Gou Rui”
   Import-Package：定义bundle所依赖的外部代码，其格式和Export-Package相同，并且也可以使用修饰词来修饰包。修饰词是用来限制所依赖包的范围的，类似过滤器，而不像Export-Package中用来声明包的特征。例如：Import-Package: org.serc.helloworld; vendor=”SERC”

** 2019-07-26
java classloader和osgi classloader
java classloader是以继承关系相互连接，依据双亲委派模型来加载类。java classloader中，应用的class都被同一个classloader加载，即class之间不存在隔离。
OSGi则提供一种不同的方式来使用classloader。它并没有采用基于继承的方式而是使用了一种叫Classloader Chaining的概念，它允许细粒度的控制每个类之间的可见性。在一个上下文中，每个组件(Bundle)与一个专有的Classloader所关联。根据组件(Bundle)的配置(manifest.mf)，Classloader可以被连接到当前组件(Bundle)之外的其他组件(Bundle)的Classloader。但是在默认情况下，所有class都不能看到除自身之外的其他组件的class。因此我们必须通过在manifest文件中配置相应的package来显式的导入或导出它们。

高并发下库存超卖问题
直接的处理方式是采用db事务。
在高并发大量请求的场景下，不能让所有请求都进入，需在前端拦截掉大部分流量。前端可操作方案为：扩容，静态化，限流，有损服务

后端方案，主要讨论写的问题，读的问题通过增加cache可以很容易的解决
1. 首先MySQL自身对于高并发的处理性能就会出现问题，一般来说，MySQL的处理性能会随着并发thread上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，最终甚至会比单thread的性能还要差
2. 其次，超卖的根结在于减库存操作是一个事务操作，需要先select，然后insert，最后update -1。最后这个-1操作是不能出现负数的，但是当多用户在有库存的情况下并发操作，出现负数这是无法避免的
3. 最后，当减库存和高并发碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢InnoDB行锁的问题，导致出现互相等待甚至死锁，从而大大降低MySQL的处理性能，最终导致前端页面出现超时异常。


淘宝的高大上方案
1. 关闭死锁检测，提高并发处理性能
2. 修改源代码，将排队提到进入引擎层前，降低引擎层面的并发度
3. 组提交，降低server和引擎的交互次数，降低IO消耗

可选方案1
将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，并且由于Redis的写性能和读性能都远高于MySQL，这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。
优点：解决性能问题

缺点：没有解决超卖问题，同时由于异步写入DB，存在某一时刻DB和Redis中数据不一致的风险

可选方案2
引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。

优点：解决超卖问题，略微提升性能。

缺点：性能受限于队列处理机处理性能和DB的写入性能中最短的那个，另外多商品同时抢购的时候需要准备多条队列

可选方案3
　　将提交操作变成两段式，先申请后确认。然后利用Redis的原子自增操作（相比较MySQL的自增来说没有空洞），同时利用Redis的事务特性来发号，保证拿到小于等于库存阀值的号的人都可以成功提交订单。然后数据异步更新到DB中。

　　优点：解决超卖问题，库存读写都在内存中，故同时解决性能问题。

　　缺点：由于异步写入DB，可能存在数据不一致。另可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为0，但是订单数并没有达到库存阀值。

** 2019-08-05
docker应用到panshi部署中的思考
1. docker能够保持跨环境的一致性
2. 将程序包与环境打包成docker文件，随时迁移
* 分布式
分布式系统是一个硬件或软件组件分布在不同网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统

** 分布式系统的特点
1. 分布性
2. 对等性
3. 并发性
4. 缺乏全局时钟

** 分布式系统的问题
1. 通信异常
2. 网络分区--脑裂
3. 三态
   成功、失败和超时
4. 节点故障

** acid
1. atomicity
2. consistency
3. isolation
4. durability

** 事务隔离级别 (隔离性isolation继续细分)
1. read uncommitted
2. read committed
3. repeatable read
4. serializable

** cap猜想
1. consistency
2. availability
3. partition tolerance

    一个分布式系统不可能同时满足以上三个特性要求；

** base理论
1. basically available (基本可用)
2. soft state (软状态)
3. eventually consistency (最终一致性)

** 最终一致性的5个变种
1. causal consistency (因果一致性)
2. read your write (读己之所写)
3. session consistency (会话一致性)
4. monotonic read consistency (单调读一致性)
5. monotonic write consistency (单调写一致性)


** 一致性协议
   主要有2pc，3pc和paxos算法

   2pc和3pc，在分布式系统中，虽然每个能够明确知道自己进行事务操作的成功或失败，但却无法知道其他分布式节点的操作结果。因此，当一个事务操作涉及跨分布式节点时，为了保持事务处理的acid特性，就需要引入一个成为“协调者（Coordinator）”的组件来统一调度所有分布式节点的执行逻辑。而被调度的分布式节点则成为“参与者（Participant）”

** 2PC
*** 阶段一：提交事务请求
    1. 事务询问
       协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的相应；
    2. 执行事务
       各参与者节点执行事务操作，并将undo和redo信息记入事务日志；
    3. 各参与者向协调者反馈事务询问的相应
       如果参与者成功执行了事务操作，那么反馈给协调者yes，否则no


    此阶段又称为”投票阶段”

*** 阶段二：执行事务提交
    协调者根据参与者反馈的情况决定最终是否可以进行事务提交操作，正常情况下，存在两种可能；
**** 执行事务提交
     假设协调者从所有参与者获得的反馈都是yes，那么就会执行事务提交
     1. 发送提交请求
        协调者向所有参与者发送commit请求；
     2. 事务提交
        参与者接收到commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的资源
     3. 反馈事务提交结果
        参与者在完成事务提交后，向协调者发送ack消息
     4. 完成事务
        协调者收到所有参与者反馈的ack消息后，完成事务
